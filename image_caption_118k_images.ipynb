{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_PRumhZG6Mbn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f685b1d7-dcc4-4e81-c6f7-f32b2d30e8fd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-08-05 06:31:03--  http://images.cocodataset.org/zips/train2017.zip\n",
            "Resolving images.cocodataset.org (images.cocodataset.org)... 16.15.217.234, 54.231.225.185, 52.217.198.1, ...\n",
            "Connecting to images.cocodataset.org (images.cocodataset.org)|16.15.217.234|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 19336861798 (18G) [application/zip]\n",
            "Saving to: ‘train2017.zip’\n",
            "\n",
            "train2017.zip       100%[===================>]  18.01G  60.2MB/s    in 8m 10s  \n",
            "\n",
            "2025-08-05 06:39:14 (37.6 MB/s) - ‘train2017.zip’ saved [19336861798/19336861798]\n",
            "\n",
            "--2025-08-05 06:42:33--  http://images.cocodataset.org/annotations/annotations_trainval2017.zip\n",
            "Resolving images.cocodataset.org (images.cocodataset.org)... 52.216.220.97, 3.5.27.189, 3.5.29.64, ...\n",
            "Connecting to images.cocodataset.org (images.cocodataset.org)|52.216.220.97|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 252907541 (241M) [application/zip]\n",
            "Saving to: ‘annotations_trainval2017.zip’\n",
            "\n",
            "annotations_trainva 100%[===================>] 241.19M  55.8MB/s    in 4.8s    \n",
            "\n",
            "2025-08-05 06:42:38 (50.7 MB/s) - ‘annotations_trainval2017.zip’ saved [252907541/252907541]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "\n",
        "!wget http://images.cocodataset.org/zips/train2017.zip\n",
        "!unzip -q train2017.zip -d coco/\n",
        "!wget http://images.cocodataset.org/annotations/annotations_trainval2017.zip\n",
        "!unzip -q annotations_trainval2017.zip -d coco/\n",
        "\n",
        "import json, os\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "import string\n",
        "from PIL import Image\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications.inception_v3 import InceptionV3, preprocess_input\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.layers import Input, Dense, LSTM, Embedding, Dropout, Add\n",
        "from tensorflow.keras.models import Model"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import json\n",
        "import string\n",
        "import pickle\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.applications.inception_v3 import InceptionV3, preprocess_input\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "\n",
        "ann_path = \"/content/coco/annotations/captions_train2017.json\"\n",
        "img_dir = \"/content/coco/train2017\"\n",
        "\n",
        "\n",
        "print(\"Loading annotations...\")\n",
        "with open(ann_path, 'r') as f:\n",
        "    annotations = json.load(f)\n",
        "\n",
        "\n",
        "image_id_to_file = {img['id']: img['file_name'] for img in annotations['images']}\n",
        "\n",
        "\n",
        "descriptions = {}\n",
        "for ann in annotations['annotations']:\n",
        "    img_id = ann['image_id']\n",
        "    caption = ann['caption'].lower().translate(str.maketrans('', '', string.punctuation))\n",
        "    fname = image_id_to_file[img_id]\n",
        "    descriptions.setdefault(fname, []).append(\"startseq \" + caption + \" endseq\")\n",
        "\n",
        "print(\"Total images with captions:\", len(descriptions))\n",
        "\n",
        "\n",
        "print(\"Loading InceptionV3 model...\")\n",
        "base_model = InceptionV3(weights='imagenet')\n",
        "cnn_model = Model(inputs=base_model.input, outputs=base_model.layers[-2].output)\n",
        "\n",
        "\n",
        "batch_size = 128\n",
        "features = {}\n",
        "output_file = \"/content/features.pkl\"\n",
        "save_every = 1000\n",
        "image_files = list(descriptions.keys())\n",
        "\n",
        "print(f\"Starting feature extraction for {len(image_files)} images...\")\n",
        "\n",
        "\n",
        "for i in tqdm(range(0, len(image_files), batch_size)):\n",
        "    batch_files = image_files[i:i+batch_size]\n",
        "    batch_images = []\n",
        "    valid_files = []\n",
        "\n",
        "    for fname in batch_files:\n",
        "        path = os.path.join(img_dir, fname)\n",
        "        if not os.path.exists(path):\n",
        "            continue\n",
        "        img = image.load_img(path, target_size=(299, 299))\n",
        "        x = image.img_to_array(img)\n",
        "        x = preprocess_input(x)\n",
        "        batch_images.append(x)\n",
        "        valid_files.append(fname)\n",
        "\n",
        "    if len(batch_images) == 0:\n",
        "        continue\n",
        "\n",
        "    batch_images = np.array(batch_images)\n",
        "\n",
        "\n",
        "    batch_features = cnn_model.predict(batch_images, verbose=0)\n",
        "\n",
        "\n",
        "    for j, fname in enumerate(valid_files):\n",
        "        features[fname] = batch_features[j]\n",
        "\n",
        "\n",
        "    if (i + batch_size) % save_every == 0:\n",
        "        with open(output_file, \"wb\") as f:\n",
        "            pickle.dump(features, f)\n",
        "        print(f\"Checkpoint saved: {len(features)} images processed\")\n",
        "\n",
        "\n",
        "with open(output_file, \"wb\") as f:\n",
        "    pickle.dump(features, f)\n",
        "\n",
        "print(f\"Feature extraction complete! Total images processed: {len(features)}\")\n",
        "print(f\"Features saved to {output_file}\")"
      ],
      "metadata": {
        "id": "HpgsVUYI6XN5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a08909dd-0bf2-4ea5-eeaf-ebcaee27f090"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading annotations...\n",
            "Total images with captions: 118287\n",
            "Loading InceptionV3 model...\n",
            "Starting feature extraction for 118287 images...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 14%|█▎        | 125/925 [03:58<24:33,  1.84s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Checkpoint saved: 16000 images processed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 27%|██▋       | 250/925 [07:31<19:36,  1.74s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Checkpoint saved: 32000 images processed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 41%|████      | 375/925 [10:57<16:18,  1.78s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Checkpoint saved: 48000 images processed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 54%|█████▍    | 500/925 [14:27<15:29,  2.19s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Checkpoint saved: 64000 images processed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 68%|██████▊   | 625/925 [18:07<19:46,  3.95s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Checkpoint saved: 80000 images processed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 81%|████████  | 750/925 [21:47<11:22,  3.90s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Checkpoint saved: 96000 images processed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 95%|█████████▍| 875/925 [25:18<03:02,  3.65s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Checkpoint saved: 112000 images processed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 925/925 [26:54<00:00,  1.75s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Feature extraction complete! Total images processed: 118287\n",
            "Features saved to /content/features.pkl\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_BSVz4F_VkWe"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}